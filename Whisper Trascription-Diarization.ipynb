{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP2tzbswsGiyldiKZqDSHSx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Συμπέρασμα:** To Diarization πολύ κακό!\n","\n","Γενικά μπορείς να κάνεις clone ένα it repo και να δουλέψεις χωρίς API KEY (MIT License) για το transcription case"],"metadata":{"id":"0TDgLgn5A6EH"}},{"cell_type":"code","source":["!pip install git+https://github.com/openai/whisper.git\n","!sudo apt update && sudo apt install ffmpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4M4ArHlA4Yj","executionInfo":{"status":"ok","timestamp":1764688871107,"user_tz":-120,"elapsed":19590,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"ac11fa84-7ce0-4f58-92d5-cba5cb28e04c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-cbuern68\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-cbuern68\n","  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (10.8.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.12.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.9.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (3.5.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2025.11.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.11.1.6)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.11.12)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.3)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=555ac6f1a8046923035323975f68c8e3b5ce5f74ed7b082be0ea7ecd5ebe5364\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-zghp8e59/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","Successfully installed openai-whisper-20250625\n","Hit:1 https://cli.github.com/packages stable InRelease\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,157 kB]\n","Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,498 kB]\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n","Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,597 kB]\n","Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n","Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n","Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n","Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n","Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,839 kB]\n","Fetched 37.5 MB in 3s (12.7 MB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n"]}]},{"cell_type":"code","source":["!whisper \"Stanford_lecture.mp4\" --model medium.en  #me to base.en επαιρνα skating laws..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evka8x2uaELt","executionInfo":{"status":"ok","timestamp":1764636159540,"user_tz":-120,"elapsed":36073,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"80f34273-f163-4cee-c77f-f43d2d26a75d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["100%|█████████████████████████████████████| 1.42G/1.42G [00:15<00:00, 98.7MiB/s]\n","[00:00.000 --> 00:02.840]  talk about what data do we train on.\n","[00:02.840 --> 00:06.760]  So my hot take is that data is the most important thing\n","[00:06.760 --> 00:09.000]  in getting language models right.\n","[00:09.000 --> 00:11.000]  So Tatsu might disagree with this.\n","[00:11.000 --> 00:14.440]  He thinks scaling laws is the most important thing.\n"]}]},{"cell_type":"code","source":["!whisper \"Stanford_lecture.mp4\" --model base.en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLzN3RiwhPxv","executionInfo":{"status":"ok","timestamp":1764636354603,"user_tz":-120,"elapsed":6234,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"92ac9e36-7d6e-4c6e-d171-7fa2a5631336"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[00:00.000 --> 00:02.840]  and talk about what data do we train on.\n","[00:02.840 --> 00:06.760]  So, my hot take is that data is the most important thing\n","[00:06.760 --> 00:09.000]  in getting language models right.\n","[00:09.000 --> 00:11.000]  So, Totsu might disagree with us.\n","[00:11.000 --> 00:13.640]  He thinks skating laws is the most important thing.\n"]}]},{"cell_type":"code","source":["!whisper \"Stanford_lecture.mp4\" --model medium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABMWiCM-g2cV","executionInfo":{"status":"ok","timestamp":1764636239989,"user_tz":-120,"elapsed":40493,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"9df381be-ecee-4e7c-8cb6-950570866335"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["100%|█████████████████████████████████████| 1.42G/1.42G [00:19<00:00, 77.8MiB/s]\n","Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n","Detected language: English\n","[00:00.000 --> 00:05.760]  talk about what data do we train on. So my hot take is that data is the most\n","[00:05.760 --> 00:10.320]  important thing in getting language models right. So Tatsu might disagree\n","[00:10.320 --> 00:15.080]  with us. He thinks skating laws is the most important thing.\n"]}]},{"cell_type":"markdown","source":["######  Try larger file"],"metadata":{"id":"PfrD7ZCphhlz"}},{"cell_type":"code","source":["!whisper \"Pitas_lecture.mp4\" --model medium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyaxqnibhpGd","executionInfo":{"status":"ok","timestamp":1764636949907,"user_tz":-120,"elapsed":27504,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"8a4ceef0-17d3-4323-a85d-d6ce1790b7c6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n","Detected language: Greek\n","[00:00.000 --> 00:04.500]  Θα ήθελα να πω ότι εμείς δεν επιδιώκουμε απλά την ενημέρωση,\n","[00:04.500 --> 00:12.500]  αλλά κάνουμε μία προσπάθεια για κατανόηση και πρόθυση συζητήσεων πάνω σε επιστημονικά θέματα.\n","[00:12.500 --> 00:18.500]  Επιστεύουμε ότι η σημερινή διάλεξη θα συμβάλλει πάρα πολύ στην κατεύθυνση αυτή\n","[00:18.500 --> 00:25.000]  χάρη στο θέμα που είναι ιδιαίτερο ενδιαφέροντος, αλλά και στον εξαιρετικό μας σημερινό ομιλικό.\n","[00:25.000 --> 00:27.500]  Τώρα το θέμα είχε σχέση με την τεχνική νοημοσύνη.\n"]}]},{"cell_type":"code","source":["!whisper \"Pitas_lecture.mp4\" --model medium --language Greek"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXOKO7phkCJT","executionInfo":{"status":"ok","timestamp":1764637066867,"user_tz":-120,"elapsed":27092,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"17b12e93-803f-4380-b67e-4bc73ca6f8b3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[00:00.000 --> 00:04.500]  Θα ήθελα να πω ότι εμείς δεν επιδιώκουμε απλά την ενημέρωση,\n","[00:04.500 --> 00:12.500]  αλλά κάνουμε μία προσπάθεια για κατανόηση και πρόθυση συζητήσεων πάνω σε επιστημονικά θέματα.\n","[00:12.500 --> 00:18.500]  Επιστεύουμε ότι η σημερινή διάλεξη θα συμβάλλει πάρα πολύ στην κατεύθυνση αυτή\n","[00:18.500 --> 00:25.000]  χάρη στο θέμα που είναι ιδιαίτερο ενδιαφέροντος, αλλά και στον εξαιρετικό μας σημερινό ομιλικό.\n","[00:25.000 --> 00:27.500]  Τώρα το θέμα είχε σχέση με την τεχνική νοημοσύνη.\n"]}]},{"cell_type":"code","source":["!whisper \"Pitas_lecture.mp4\" --model large --language Greek"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9JjqOsZkUPk","executionInfo":{"status":"ok","timestamp":1764637214512,"user_tz":-120,"elapsed":105090,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"9eb78224-56b8-4f91-aed0-a6cdaf8a000c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["100%|█████████████████████████████████████| 2.88G/2.88G [00:41<00:00, 74.9MiB/s]\n","[00:00.000 --> 00:04.320]  Θα ήθελα να πω ότι εμείς δεν επιδιώκουμε απλά την ενημέρωση,\n","[00:04.580 --> 00:11.880]  αλλά κάνουμε μια προσπάθεια για κατανόηση και προώθηση συζητήσεων επάνω σε επιστημονικά θέματα.\n","[00:12.620 --> 00:18.120]  Πιστεύουμε ότι η σημερινή διάλεξη θα συμβάλλει πάρα πολύ στην κατεύθυνση αυτή,\n","[00:18.600 --> 00:24.900]  χάρη στο θέμα που είναι ιδιαίτερο ενδιαφέροντος, αλλά και στον εξαιρετικό μας σημερινό ομιλητή.\n","[00:25.220 --> 00:27.580]  Τώρα το θέμα έχει σχέση με την τεχνική νοημοσύνη.\n"]}]},{"cell_type":"code","source":["!whisper \"/content/Diarization.mp4\" --model large --language Greek"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJWhHNHqprXP","executionInfo":{"status":"ok","timestamp":1764688988067,"user_tz":-120,"elapsed":96133,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"0a294626-4241-49fd-9e99-0d2e84d4960a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["100%|█████████████████████████████████████| 2.88G/2.88G [00:39<00:00, 78.2MiB/s]\n","[00:00.000 --> 00:06.480]  Δεν θα πιεστώ με τα πιο σημαντικά, τα φιλοσοφικά, γιατί από ό,τι κατάλαβα θέλει να τα αποφύγει.\n","[00:07.440 --> 00:08.960]  Α, όχι, δεν θέλω να τα αποφύγω.\n","[00:10.360 --> 00:13.840]  Ναι, είναι πολύ πλατιάζει η συζήτηση.\n"]}]},{"cell_type":"markdown","source":["#### Alternative"],"metadata":{"id":"fw-KQcAYksRt"}},{"cell_type":"code","source":["!pip install -U openai-whisper"],"metadata":{"id":"n6oc_h1Tkul-","executionInfo":{"status":"ok","timestamp":1764689115317,"user_tz":-120,"elapsed":38,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import whisper\n","\n","model = whisper.load_model(\"turbo\")\n","result = model.transcribe(\"Stanford_lecture_short.mp4\")\n","print(result[\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEHBS34kk_hq","executionInfo":{"status":"ok","timestamp":1764671236989,"user_tz":-120,"elapsed":15347,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"51c8d174-e824-43a9-f572-2afc68f708e9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":[" talk about what data do we train on. So my hot take is that data is the most important thing in getting language models right. So Tatsu might disagree with this. He thinks skating laws is the most important thing.\n"]}]},{"cell_type":"code","source":["print(result[\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68_VfNR_l1em","executionInfo":{"status":"ok","timestamp":1764671254328,"user_tz":-120,"elapsed":60,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"2ff611f5-17e7-427a-e47b-48c593466116"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[" talk about what data do we train on. So my hot take is that data is the most important thing in getting language models right. So Tatsu might disagree with this. He thinks skating laws is the most important thing.\n"]}]},{"cell_type":"markdown","source":["#### Transcription"],"metadata":{"id":"LRkeH3tC59LA"}},{"cell_type":"code","source":["#Alternative\n","from openai import OpenAI\n","\n","api_key= \"\"#process.env.JWT_SECRET;\n","client = OpenAI(api_key=api_key)\n","audio_file= open(\"/content/Pitas_lecture.mp4\", \"rb\")\n","\n","transcription = client.audio.transcriptions.create(\n","    model=\"gpt-4o-transcribe\",\n","    #model=\"whisper-1\",\n","    file=audio_file\n",")\n","\n","print(transcription.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnRfhFkQW2_S","executionInfo":{"status":"ok","timestamp":1764685066181,"user_tz":-120,"elapsed":3739,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"7b4972fa-bf2c-484e-f72e-2b7ca6468fe0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Δεν επιδιώκουμε απλά την ενημέρωση, αλλά κάνουμε μια προσπάθεια για κατανόηση και προώθηση συζητήσεων επάνω σε επιστημονικά θέματα. Πιστεύουμε ότι η σημερινή διάλεξη θα συμβάλει πάρα πολύ στην κατεύθυνση αυτή, χάρη στο θέμα που είναι ιδιαίτερο ενδιαφέροντος αλλά και στον εξαιρετικό μας σημερινό ομιλική. Τώρα το θέμα έχει σχέση με την τεχνική νοημοσύνη.\n"]}]},{"cell_type":"markdown","source":["#### Diarization  with gpt-4o-transcribe-diarize"],"metadata":{"id":"dk80tqPM54DR"}},{"cell_type":"code","source":["#Diarization  with gpt-4o-transcribe-diarize\n","import base64\n","from openai import OpenAI\n","\n","client = OpenAI(api_key=api_key)\n","#path=\"/content/Pitas_lecture.mp4\"\n","\n","\n","#def to_data_url(path: str) -> str:\n","#    with open(path, \"rb\") as fh:\n","#        return \"data:audio/wav;base64,\" + base64.b64encode(fh.read()).decode(\"utf-8\")\n","\n","with open(\"/content/Diarization.mp4\", \"rb\") as audio_file:\n","    transcript = client.audio.transcriptions.create(\n","        model=\"gpt-4o-transcribe-diarize\",\n","        file=audio_file,\n","        response_format=\"diarized_json\",\n","        chunking_strategy=\"auto\",\n","        #extra_body={\n","        #    \"known_speaker_names\": [\"agent\"],\n","        #    \"known_speaker_references\": [to_data_url(\"/content/Pitas_lecture.mp4\")],\n","        #},\n","    )\n","\n","for segment in transcript.segments:\n","    print(segment.speaker, segment.text, segment.start, segment.end)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aotaib9-cXPG","executionInfo":{"status":"ok","timestamp":1764685402354,"user_tz":-120,"elapsed":26944,"user":{"displayName":"Anthoula Mountzouri","userId":"17466475986029133911"}},"outputId":"9ad224ff-ebb0-404d-befc-3fa8e05decd7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["A  Βέβαια ποιος το μετά πιο σημαντικά τα φιλοσοφικά γιατί έχω την κατάλαβα θέλει να τα αποφύγει είναι 0.050000000000000044 6.999999999999999\n","B  Όχι, δεν θέλω να τα αποφύγω. 6.999999999999999 8.9\n","A  πολύ πλατιάς η συζήτηση 10.6 13.75\n"]}]}]}